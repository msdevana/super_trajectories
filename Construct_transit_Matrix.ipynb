{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib.path import Path\n",
    "import numpy as np\n",
    "import gsw\n",
    "import warnings\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import cmocean\n",
    "from collections import OrderedDict\n",
    "import seaborn as sns\n",
    "warnings.filterwarnings(action='once')\n",
    "import os\n",
    "import cartopy.feature as cfeature\n",
    "import glob\n",
    "from tqdm import tqdm as bar\n",
    "from dask import delayed\n",
    "import dask\n",
    "from shapely.geometry import Polygon, Point, MultiPoint\n",
    "from numba import jit\n",
    "from dask.diagnostics import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/oceans/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n"
     ]
    }
   ],
   "source": [
    "# look first at the gps one (its a smaller dataset)\n",
    "path = '/Users/manishdevana/Research/data_storage/surface_drifter_data/*.nc'\n",
    "files = glob.glob(path)\n",
    "files\n",
    "\n",
    "gps = xr.open_dataset(files[0])\n",
    "\n",
    "# if you want to include/exclude drogued drifters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/oceans/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# choose points in the zone you want\n",
    "lons = gps.LON.values\n",
    "lats = gps.LAT.values\n",
    "times = gps.TIME.values\n",
    "ids = gps.ID.values\n",
    "\n",
    "# define a box\n",
    "spg_lon = [5, 360-40]\n",
    "spg_lat = [40, 85]\n",
    "\n",
    "# mask based on box\n",
    "lonmask = np.logical_and(lons>=spg_lon[0], lons<= spg_lon[1])\n",
    "latmask = np.logical_and(lats>=spg_lat[0], lats<= spg_lat[1])\n",
    "\n",
    "# masking\n",
    "mask = np.logical_and(lonmask, latmask)\n",
    "ids2 = ids[mask]\n",
    "\n",
    "# The individual drifter float ids (indexing this way seems to be much quicker(not sure why  though))\n",
    "drifters = np.unique(ids2) \n",
    "drifters = drifters[np.isfinite(drifters)]\n",
    "\n",
    "# The new dataset\n",
    "gps2 = gps.sel(TIME=gps.ID.isin(drifters))\n",
    "\n",
    "# reorganize data into a list of datarrays where each array is a drifter tied to a single id\n",
    "modified_drifts = []\n",
    "for drifter in drifters:\n",
    "    traj = gps2.sel(TIME=gps2.ID==drifter)\n",
    "    dt = traj.TIME.diff(dim='TIME').values.astype(float)/1e9/60/60/24\n",
    "#     step = np.ceil((len(dt)+1)/step_size).astype(int)\n",
    "    \n",
    "    trev = np.hstack((0,np.cumsum(dt)))\n",
    "    new_ds = xr.Dataset({\n",
    "        'lon':(['time'], traj.LON.values),\n",
    "        'lat':(['time'], traj.LAT.values),\n",
    "        # add u and v later\n",
    "    },\n",
    "        coords={\n",
    "            'time':trev\n",
    "        }\n",
    "        \n",
    "    )\n",
    "    modified_drifts.append(new_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/oceans/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# functions:\n",
    "\n",
    "def prep_fields_and_trajs(modified_drift_set, data_dt = 1/24, resolution=0.25, lonlims=[], latlims=[]):\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # the drifter dataset is on a 0-360 longitude grid\n",
    "    lon = np.arange(360+lonlims[0], 360+(lonlims[1]+resolution), resolution)\n",
    "    lat = np.arange(latlims[0], latlims[1]+resolution, resolution)\n",
    "    \n",
    "    # Make a list of polygons using the lat long grid\n",
    "\n",
    "    B = [] # This is the set of boxes B\n",
    "    for k in range(1, lat.shape[0]):\n",
    "        for i in range(1, lon.shape[0]):\n",
    "             B.append([\n",
    "                lon[i-1], lat[k-1],\n",
    "                lon[i], lat[k]\n",
    "\n",
    "            ])\n",
    "                \n",
    "    # put all the trajectories on to a uniform time grid starting at 0\n",
    "    \n",
    "    # make the tiem grid as long as the longest trajectory\n",
    "    lens = []\n",
    "    for d in modified_drift_set:\n",
    "        lens.append(len(d.lon))\n",
    "\n",
    "    max_l = np.nanmax(lens)\n",
    "    trev = np.linspace(0, max_l*data_dt, max_l)\n",
    "    \n",
    "    # now nan pad all the trajecotories with nan to be same lenght\n",
    "    drift_lon = []\n",
    "    drift_lat = []\n",
    "    for d in modified_drifts:\n",
    "        nan_block = np.full(max_l - d.time.shape[0], np.nan)\n",
    "        # adds nan to the end of the array \n",
    "        drift_lon.append(np.hstack((d.lon.values, nan_block)))\n",
    "        drift_lat.append(np.hstack((d.lat.values, nan_block)))\n",
    "\n",
    "\n",
    "    xx = np.array(drift_lon) # lon of drifters\n",
    "    yy = np.array(drift_lat) # lat of drifters\n",
    "    \n",
    "    return B, xx, yy\n",
    "\n",
    "\n",
    "def split_traj( xx, yy, T=1, data_dt=1/24):\n",
    "    \"\"\"\n",
    "    # This splits all the trajectories into pairs seperated by T = timestep\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    subtraj = []\n",
    "    steps = int(T/data_dt)\n",
    "    for i in range(len(xx[:,0]) - steps):\n",
    "        x0 = xx[:,i]\n",
    "        y0 = yy[:,i]\n",
    "        x1 = xx[:,i+steps]\n",
    "        y1 = yy[:,i+steps]\n",
    "        subtraj.append(np.stack([x0, y0, x1, y1]).T)\n",
    "\n",
    "\n",
    "    subtraj = np.vstack(subtraj) # all subtrajectory pairs\n",
    "    # clean up ones that have nans\n",
    "    mask = np.sum(np.isfinite(subtraj), axis=1) == 4\n",
    "    subtraj = subtraj[mask, :]\n",
    "    \n",
    "    return subtraj\n",
    "\n",
    "    \n",
    "    \n",
    "# now compute the Probality Matrix values\n",
    "def FindInside(box, points): \n",
    "    x = points[:, 0]\n",
    "    y = points[:, 1]\n",
    "    loncheck = np.logical_and(box[0] < x, box[2] > x)\n",
    "    latcheck = np.logical_and(box[1] < y, box[3] > y)\n",
    "    inside = np.logical_and(loncheck, latcheck)\n",
    "    \n",
    "    return inside\n",
    "\n",
    "def _insideTest(box, x, y):\n",
    "    \n",
    "    loncheck = np.logical_and(box[0] < x, box[2] > x)\n",
    "    \n",
    "    latcheck = np.logical_and(box[1] < y, box[3] > y)\n",
    "    inside = np.logical_and(loncheck, latcheck)\n",
    "    if np.sum(inside) == 0:\n",
    "        return False\n",
    "    elif np.sum(inside) == 1:\n",
    "        return True\n",
    "    else:\n",
    "        print('fuck up')\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def TestInside(boxes, point):\n",
    "    \n",
    "    x = point[0]\n",
    "    y = point[1]\n",
    "    \n",
    "    test = [_insideTest(box, x, y) for box in boxes]\n",
    "    \n",
    "    return int(np.where(test)[0])\n",
    "\n",
    "    \n",
    "\n",
    "def FindInsideCount(box, points): \n",
    "    x = points[:, 0]\n",
    "    y = points[:, 1]\n",
    "    loncheck = np.logical_and(box[0] < x, box[2] > x)\n",
    "    latcheck = np.logical_and(box[1] < y, box[3] > y)\n",
    "    inside = np.logical_and(loncheck, latcheck)\n",
    "    \n",
    "    return np.nansum(inside)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# @jit(parallel=True)\n",
    "def FindNextCount(boxes, points):\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    inside = np.array([FindInside(box,  points) for box in boxes]).T\n",
    "    mask = np.sum(inside, axis=1)\n",
    "    mask = mask == 1\n",
    "    \n",
    "    counts = np.sum(inside[mask, :], axis=0)\n",
    "    \n",
    "    #filter the ones that leave the domain\n",
    "    \n",
    "    # Ni revised to remove drifters that leave domain\n",
    "    Ni = np.sum(mask)\n",
    "    \n",
    "    return counts, Ni\n",
    "    \n",
    "    \n",
    "\n",
    "def construct_transit_matrix(B, subtraj):\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    P1 = np.zeros((len(B), len(B))) # square matrix with dimension M = len(B)\n",
    "    for i in bar(range(len(B))):\n",
    "        Bij = B[i]\n",
    "    #     points = \n",
    "\n",
    "        # first find all the points inside the current box\n",
    "        inside = FindInside(Bij, subtraj[:, :2])\n",
    "\n",
    "        # find the new box after one timestep from box i\n",
    "        if np.sum(inside) > 0:\n",
    "\n",
    "            counts, Ni = FindNextCount(B, subtraj[inside, 2:])\n",
    "\n",
    "            # convert to probability\n",
    "            if Ni > 0:\n",
    "                Pij = counts/Ni\n",
    "                if np.round((np.sum(Pij)), 1) != 1:\n",
    "                    print('You messed up')\n",
    "                    break\n",
    "                P1[i,:] = Pij\n",
    "                \n",
    "        \n",
    "    return P1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32000/32000 [03:53<00:00, 136.98it/s]\n"
     ]
    }
   ],
   "source": [
    "# do the transit matrix calculation\n",
    "\n",
    "# Parameters:\n",
    "resolution = 0.25\n",
    "lonlims = [-40, 0]\n",
    "latlims = [35, 85]\n",
    "data_dt = 1/24 # i do the timesteps and time grids in decimal dayys and the drifter data is at 1 hour res\n",
    "T = 2 # fixed timestep length for subtrajectoires\n",
    "# do the prep\n",
    "B, xx, yy = prep_fields_and_trajs(modified_drifts, \n",
    "                          data_dt=data_dt, \n",
    "                          resolution=resolution,\n",
    "                          lonlims=lonlims,\n",
    "                          \n",
    "                                  latlims=latlims\n",
    "                         )\n",
    "\n",
    "\n",
    "# split into subtrajectories\n",
    "subtrajectories = split_traj(xx, yy, T=T, data_dt=data_dt)\n",
    "\n",
    "\n",
    "# final transit matrix\n",
    "P = construct_transit_matrix(B, subtrajectories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('P_tester_0.25_res.npy', P)\n",
    "np.save('boxes_0.25_res.npy',B,  allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
